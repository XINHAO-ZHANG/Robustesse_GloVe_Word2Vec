{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "045b8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def read_embedding(path):\n",
    "    vocab = []\n",
    "    word_embedding = []\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        for i in f.readlines():\n",
    "            cut_data = i.split()\n",
    "            vocab.append(cut_data[0])\n",
    "            word_embedding.append(list(map(float,cut_data[1:])))\n",
    "\n",
    "    word_to_idx = {}\n",
    "    for number, word in enumerate(vocab):\n",
    "        word_to_idx[word] = number\n",
    "    return vocab, word_embedding, word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "846ac4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simcos(a,b):\n",
    "    dot = sum(a*b)\n",
    "    mod_a = sum(a**2)**0.5\n",
    "    mod_b = sum(b**2)**0.5\n",
    "    return dot/(mod_a*mod_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e65126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sim(word_embedding, word_to_idx, word_name):\n",
    "    np_embedding = np.array(word_embedding)\n",
    "\n",
    "    all_sim = []\n",
    "    for i in range(len(word_embedding)):\n",
    "        all_sim.append([simcos(np_embedding[word_to_idx[word_name]],np_embedding[i]),i])\n",
    "    all_sim.sort(reverse=True,key=lambda x:x[0])\n",
    "    return all_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7a9d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top20_words(sims, vocab):\n",
    "    top20 = sims[1:21]\n",
    "#     words_with_scores = [(vocab[i[1]], i[0]) for i in top20]\n",
    "    words = [vocab[i[1]] for i in top20]\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0273a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vovab, glove_embedding, glove_to_idx = read_embedding('./vectors_glove.txt')\n",
    "word2vec_vovab, word2vec_embedding, word2vec_to_idx = read_embedding('./vectors_word2vec.txt')\n",
    "with open('vocab_train.txt', 'r', encoding='utf-8') as f:\n",
    "    top = []\n",
    "    for i in range(20):\n",
    "        line = f.readline()\n",
    "        top.append(line.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e51dfc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name:the \n",
      "glove_top20_words:['of', 'place', 'other', 'in', 'out', 'world,', 'way', 'edge', 'at', 'put', 'through', 'if', 'whole', 'rest', 'could', 'world', 'near', 'a', 'found', 'back'] \n",
      "w2v_top20_words:['of', 'in', 'and', 'which', 'a', 'by', 'their', 'his', 'from', 'this', 'on', 'The', 'Tokugawa', 'traverse', 'farthest', 'ladders', 'absorbed.', 'uninhabited', 'Shgun', 'Shgunate,']\n",
      "word_name:and \n",
      "glove_top20_words:['to', 'in', 'could', 'of', 'even', 'looked', 'them', 'then', 'have', 'had', 'time,', 'went', 'the', 'put', 'him,', 'felt', 'now', 'it,', 'back', 'if'] \n",
      "w2v_top20_words:['the', 'with', 'when', 'then', 'in', 'but', 'their', 'by', 'as', 'while', 'his', 'them', 'of', 'to', 'they', 'and,', 'for', 'her', 'which', 'him']\n",
      "word_name:of \n",
      "glove_top20_words:['the', 'sort', 'midst', 'presence', 'instead', 'life.', 'in', 'kind', 'out', 'those', 'life,', 'knowledge', 'and', 'think', 'one', 'rest', 'life', 'it.', 'pleasure', 'of,'] \n",
      "w2v_top20_words:['the', 'in', 'which', 'preserves', 'affords', 'by', 'collective', 'regulating', 'analogous', 'primitive', 'production', 'extermination', 'namely,', 'sexes,', 'and', 'geographical', 'himin', 'unanimous', 'Sparta.', 'failures']\n",
      "word_name:to \n",
      "glove_top20_words:['able', 'seemed', 'give', 'to,', 'forced', 'going', 'show', 'unable', 'him', 'determined', 'and', 'take', 'speak,', 'tried', 'listen', 'have', 'him,', 'see', 'say', 'trying'] \n",
      "w2v_top20_words:['would', 'that', 'for', 'him', 'should', 'but', 'not', 'it', 'might', 'and', 'he', 'if', 'could', 'me', 'dissuade', 'further.', 'I', 'so', 'them', 'him.']\n",
      "word_name:a \n",
      "glove_top20_words:['sort', 'such', 'man', 'have', 'look', 'one.', 'kind', 'single', 'him', 'place', 'if', 'man,', 'the', 'fancy', 'with', 'another', 'person', 'gave', 'mere', \"'a\"] \n",
      "w2v_top20_words:['the', 'of', 'this', 'in', 'another', 'A', 'some', \"'a\", 'little', 'an', 'stout,', 'and', 'was', 'with', 'cookshop', 'every', 'duck.', 'uncomfortably', 'built.', 'his']\n",
      "word_name:in \n",
      "glove_top20_words:['the', 'of', 'and', 'midst', 'place', 'case', 'order', 'spite', 'found', 'faith', 'put', 'front', 'back', 'way', 'that', 'In', 'world', 'with', 'company', 'he'] \n",
      "w2v_top20_words:['of', 'the', 'and', 'by', 'into', 'with', 'In', 'a', 'which', 'from', 'his', 'chilling', 'on', 'customs,', 'namely,', 'constructed', 'befitting', 'Shgun', 'wherein', 'sumptuous']\n",
      "word_name:I \n",
      "glove_top20_words:['am', 'know', 'see', 'have', 'if', 'think', 'say', 'want', 'believe', 'wish', 'do', 'think,', 'tell', 'me.', 'mean', \"don't\", 'thought', 'say,', 'know.', 'should'] \n",
      "w2v_top20_words:['you', 'me', 'my', \"'I\", 'me,', '(I', 'me.', 'you,', 'am', 'myself,', 'myself', 'myself.', 'it', 'You', 'do', 'Ellen,', 'if', 'you.', 'not', 'your']\n",
      "word_name:that \n",
      "glove_top20_words:['that,', 'not', 'is', 'fact', 'know', 'this,', 'should', 'to', 'there', 'might', 'would', 'nothing', 'could', 'so', 'same', 'think', 'place', 'felt', 'case', 'also'] \n",
      "w2v_top20_words:['it', 'but', 'this', 'to', 'not', 'he', 'so', 'when', 'if', 'beforehand,', 'would', 'even', 'for', 'what', 'only', 'because', 'have', 'be', 'which', 'should']\n",
      "word_name:he \n",
      "glove_top20_words:['said,', 'if', 'him', 'could', 'moment', 'saw', 'went', 'knew', 'when', 'man', 'him,', 'He', 'looked', 'replied.', 'thought', 'though', 'had', 'say', 'But', 'ought'] \n",
      "w2v_top20_words:['him', 'his', 'him,', 'himself', 'she', 'him.', 'it', 'He', 'that', 'himself,', 'to', 'Smerdyakov', 'himself.', 'opponent', 'had', 'beforehand,', 'man', 'Lothario', 'fit.', 'and']\n",
      "word_name:was \n",
      "glove_top20_words:['It', 'There', 'was,', \"wasn't\", 'knew', 'there', 'felt', 'found', 'man', 'did', 'once', 'She', 'it', 'moment', 'had', 'that', 'am', 'thought', 'evidently', 'already'] \n",
      "w2v_top20_words:['had', 'seemed', 'felt', 'were', 'saw', 'was,', 'been', 'could', 'knew', 'appeared', 'remained', 'came', 'was.', 'became', 'disliked', 'arrival.', 'recollected', 'found', 'evidently', 'she']\n",
      "word_name:his \n",
      "glove_top20_words:['hand', 'head,', 'hands', \"master's\", 'him', \"father's\", \"wife's\", 'head', \"brother's\", 'own', 'way', 'But', 'arms,', \"Levin's\", 'hands.', 'own,', 'them', 'coat', 'heart.', 'pipe'] \n",
      "w2v_top20_words:['he', 'himself', 'him', 'him,', 'her', 'girded', 'and', 'with', 'the', 'His', \"latter's\", \"son's\", 'himself,', 'He', \"Alyosha's\", 'clenched', 'ached,', 'his,', 'him.', 'twitching']\n",
      "word_name:with \n",
      "glove_top20_words:['filled', 'covered', 'mingled', 'delight', 'smile.', 'blood.', 'accordance', 'a', 'satisfied', 'compared', 'horror.', 'of', 'sort', 'pleasure,', 'angry', 'acquainted', 'those', 'have', 'met', 'up'] \n",
      "w2v_top20_words:['and', 'his', 'in', 'sarcastic,', 'knobby', 'the', 'tawny', 'undisguised', 'irrepressible', 'wrathful', 'beaming', 'clenching', 'especial', 'a', 'flushed,', 'sparkling', 'unmoved,', 'mourning,', 'of', 'willow,']\n",
      "word_name:it \n",
      "glove_top20_words:['think', 'is.', 'it,', 'put', 'it.', 'if', 'It', 'was,', 'thought', 'way', 'all.', 'did', 'matter', 'know', 'it?', 'only', 'not', 'impossible', 'them', 'wish'] \n",
      "w2v_top20_words:['that', 'it,', 'he', 'it.', 'I', 'not', 'so', 'if', 'me', 'to', 'but', 'him', 'be', 'she', 'this', 'what', 'would', 'should', 'beforehand', 'somehow.']\n",
      "word_name:for \n",
      "glove_top20_words:['only', 'sake', 'purpose', 'him', 'food', 'me', 'reason', 'if', 'see', 'it,', 'take', 'another', 'ever,', 'prepared', 'left', 'do', 'ever.', 'get', 'I', 'it.'] \n",
      "w2v_top20_words:['to', 'but', 'that', 'and', 'so', 'for.', 'only', 'would', 'if', 'not', 'because', 'should', 'ransomed', 'any', 'I', 'all', 'reward', 'it', 'faithfully', 'sorrow.']\n",
      "word_name:is \n",
      "glove_top20_words:['It', \"'This\", 'is,', \"'It\", 'only', 'say,', 'that', 'not', 'seems', 'nothing', \"'That\", 'it', 'name', 'what', 'For', 'when', 'there', \"'He\", 'think', 'truth'] \n",
      "w2v_top20_words:['are', 'has', 'NOT', 'may', 'considers', 'will', 'can', 'does', 'rests', 'argues', 'requires', 'exists', 'is,', 'belongs', 'proves', 'just.', 'becomes', 'Impossible.', 'denies', 'explains']\n",
      "word_name:had \n",
      "glove_top20_words:['been', 'already', 'having', 'just', 'gone', 'lately', 'given', 'him.', 'brought', 'taken', 'could', 'knew', 'come', 'entered', 'left', 'once', 'him,', 'had,', 'felt', 'discovered'] \n",
      "w2v_top20_words:['was', 'been', 'having', 'arrival.', 'had,', 'were', 'arrival,', 'could', 'knew', 'recollected', 'felt', 'previously', 'seemed', 'lately', 'would', 'before,', \"hadn't\", 'he', 'visit,', 'that']\n",
      "word_name:as \n",
      "glove_top20_words:['possible.', 'regarded', 'well', 'soon', 'though', 'could,', 'possible,', \"'As\", 'usual,', 'As', 'could.', 'if', 'them', 'inasmuch', 'always', 'may', 'far', 'usual.', 'might', 'thought'] \n",
      "w2v_top20_words:['so', 'and', 'though', 'that', 'but', 'if', 'could,', 'when', 'could.', 'as,', 'to', 'readily', 'nevertheless', 'possible.', 'thoroughly,', 'possible,', 'well', 'it', 'very', 'inasmuch']\n",
      "word_name:not \n",
      "glove_top20_words:['did', 'could', 'do', 'does', 'think', 'know', 'will', 'wish', 'But', 'not,', 'should', 'must', 'if', 'it', 'have', 'would', 'are', 'see', 'understand', 'afraid'] \n",
      "w2v_top20_words:['that', 'but', 'would', 'it', 'to', 'never', 'be', 'if', 'not.', 'not,', 'I', 'only', 'should', 'did', 'otherwise.', 'so', 'what', 'you', 'do', 'no']\n",
      "word_name:you \n",
      "glove_top20_words:['do', 'Do', 'know', 'tell', 'think', 'you,', 'You', 'know,', \"'Do\", \"don't\", 'if', 'wish', 'If', 'give', 'want', 'know.', 'see', 'you?', 'think,', 'you.'] \n",
      "w2v_top20_words:['I', 'you,', 'your', 'do', 'You', 'you.', 'you...', 'me', 'myself?', \"don't\", \"'I\", 'yourself?', 'you?', 'yourself', 'yourself,', 'papa', 'yourselves', 'tell', 'yourself.', 'am']\n",
      "word_name:at \n",
      "glove_top20_words:['once.', 'once,', 'once', 'looked', 'all.', 'least', 'looking', 'last.', 'least,', 'stared', 'glanced', 'At', 'look', 'moment,', 'all,', 'arrived', 'him,', 'wonder', 'him', 'near'] \n",
      "w2v_top20_words:['At', 'intently', 'stupidly', 'uneasily', 'at.', 'after', 'at,', \"'At\", 'on', 'fearfully', 'intently,', 'saw', 'was', 'anxiously', 'inquisitively', \"'at\", 'blankly', 'wildly', 'undisguised', 'with']\n"
     ]
    }
   ],
   "source": [
    "for i in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, i)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, i)\n",
    "    glove = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "    print(f'word_name:{i} \\nglove_top20_words:{glove} \\nw2v_top20_words:{w2v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87c52c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name:the \n",
      "glove_top20_words:[('of', 0.5268502146035025), ('place', 0.44191812394257685), ('other', 0.44028620155431886), ('in', 0.41575140738021504), ('out', 0.4109586485694136), ('world,', 0.4092624149097508), ('way', 0.4089115616595994), ('edge', 0.4076800456115188), ('at', 0.40200729621021264), ('put', 0.4000822199413238), ('through', 0.3988676536853588), ('if', 0.397888296641105), ('whole', 0.3978042825021203), ('rest', 0.39638470166857726), ('could', 0.3950165589559184), ('world', 0.3935579163753763), ('near', 0.39224612797840225), ('a', 0.39223306315685774), ('found', 0.39119775956835934), ('back', 0.3889133018068038)] \n",
      "w2v_top20_words:[('of', 0.7090042875282595), ('in', 0.6355513246147906), ('and', 0.584657821789954), ('which', 0.5514658602753478), ('a', 0.48949501975097875), ('by', 0.4676654553606204), ('their', 0.4616629045251449), ('his', 0.45595447817988116), ('from', 0.4530842437053799), ('this', 0.4414289563961361), ('on', 0.4334311708497048), ('The', 0.43136005475404054), ('Tokugawa', 0.4287682561800679), ('traverse', 0.424398656902303), ('farthest', 0.42006377607497636), ('ladders', 0.41668157704388004), ('absorbed.', 0.41290706584357484), ('uninhabited', 0.4080665337405336), ('Shgun', 0.40764576949920406), ('Shgunate,', 0.4074402741587766)]\n",
      "word_name:and \n",
      "glove_top20_words:[('to', 0.43627411034985314), ('in', 0.41120608213571025), ('could', 0.4086774981192045), ('of', 0.4014854169654277), ('even', 0.39745503745859717), ('looked', 0.3971810321456291), ('them', 0.3925753466275362), ('then', 0.39042261424891117), ('have', 0.38952652815563854), ('had', 0.382970857674489), ('time,', 0.3801296340255318), ('went', 0.3792830460996903), ('the', 0.37813736301609707), ('put', 0.376548659447687), ('him,', 0.3750221729679915), ('felt', 0.3748602540880651), ('now', 0.37426449534481276), ('it,', 0.3726940486848195), ('back', 0.37166270230173576), ('if', 0.371315273812871)] \n",
      "w2v_top20_words:[('the', 0.584657821789954), ('with', 0.5473793193299815), ('when', 0.535072964769116), ('then', 0.5264370992940612), ('in', 0.5158938250017868), ('but', 0.5112702518267975), ('their', 0.48783938389556925), ('by', 0.4767280970070035), ('as', 0.4764075388306864), ('while', 0.4762714369891325), ('his', 0.4714773796131084), ('them', 0.4632205761815622), ('of', 0.4607536423221249), ('to', 0.4588901223015354), ('they', 0.4480094973257791), ('and,', 0.43382334899796066), ('for', 0.42928158153814655), ('her', 0.42617443053570025), ('which', 0.4223984676202145), ('him', 0.4213091201261009)]\n",
      "word_name:of \n",
      "glove_top20_words:[('the', 0.5268502146035025), ('sort', 0.4746544840049699), ('midst', 0.43599627365292465), ('presence', 0.42005139209385023), ('instead', 0.4191652678157031), ('life.', 0.4118701364312512), ('in', 0.411340383545046), ('kind', 0.4108664894780868), ('out', 0.41018729454007463), ('those', 0.40667187656135506), ('life,', 0.40586537091983654), ('knowledge', 0.4028785110470492), ('and', 0.4014854169654277), ('think', 0.4010492626999419), ('one', 0.39981764591466157), ('rest', 0.3990182539152755), ('life', 0.39754149450631354), ('it.', 0.39504671782488393), ('pleasure', 0.39393587321871937), ('of,', 0.3925223616847658)] \n",
      "w2v_top20_words:[('the', 0.7090042875282595), ('in', 0.6485634372291442), ('which', 0.6098008623770653), ('preserves', 0.5252841593415792), ('affords', 0.5148643101141815), ('by', 0.49143539031111694), ('collective', 0.4875559527217246), ('regulating', 0.4837974095327637), ('analogous', 0.4826635589772009), ('primitive', 0.4805004599960638), ('production', 0.47566439344693134), ('extermination', 0.4720457245034198), ('namely,', 0.47129462941099143), ('sexes,', 0.47070586777492934), ('and', 0.4607536423221249), ('geographical', 0.4604487759256208), ('himin', 0.4598556909053577), ('unanimous', 0.45966471891234323), ('Sparta.', 0.45850468532080196), ('failures', 0.4565257132481004)]\n",
      "word_name:to \n",
      "glove_top20_words:[('able', 0.4709831093162288), ('seemed', 0.46273035224002845), ('give', 0.45843415972878765), ('to,', 0.4538812641279641), ('forced', 0.4476828642260694), ('going', 0.44333481971094396), ('show', 0.4409221046839228), ('unable', 0.44020498769981425), ('him', 0.4398435240953329), ('determined', 0.43634954003358717), ('and', 0.43627411034985314), ('take', 0.4359947328545283), ('speak,', 0.43486615219517694), ('tried', 0.4339447251238601), ('listen', 0.4330991150917976), ('have', 0.43061306249194803), ('him,', 0.42887138251103984), ('see', 0.42818510251982844), ('say', 0.42559077243831805), ('trying', 0.4194233750758284)] \n",
      "w2v_top20_words:[('would', 0.59680575795137), ('that', 0.5639183481718602), ('for', 0.5619678288786758), ('him', 0.5258065839777553), ('should', 0.5132194570444815), ('but', 0.5021793343932712), ('not', 0.4985766326144632), ('it', 0.46275683693738034), ('might', 0.4607639289493399), ('and', 0.4588901223015354), ('he', 0.4572292763526859), ('if', 0.4479721384678408), ('could', 0.4361624214842619), ('me', 0.43549103159852287), ('dissuade', 0.42959501848592774), ('further.', 0.42437688583241573), ('I', 0.41502121787334256), ('so', 0.41213710636294376), ('them', 0.40740626380546013), ('him.', 0.4063742272680151)]\n",
      "word_name:a \n",
      "glove_top20_words:[('sort', 0.5146018986308326), ('such', 0.42831744814468464), ('man', 0.42149642893081835), ('have', 0.41848828561801404), ('look', 0.4167624837106344), ('one.', 0.4117628508472398), ('kind', 0.40671160058370065), ('single', 0.3987397196024401), ('him', 0.3957372922176056), ('place', 0.3955779770763829), ('if', 0.3937065124481955), ('man,', 0.3933250827375959), ('the', 0.39223306315685774), ('fancy', 0.3908694267868327), ('with', 0.39008528031634176), ('another', 0.389860327964959), ('person', 0.38894477008887696), ('gave', 0.3886023133516863), ('mere', 0.38549945997504476), (\"'a\", 0.38451171082363134)] \n",
      "w2v_top20_words:[('the', 0.48949501975097875), ('of', 0.4506139300162993), ('this', 0.4439455844054409), ('in', 0.43248300048031907), ('another', 0.4198248389699685), ('A', 0.4155947698210188), ('some', 0.41038791589740253), (\"'a\", 0.3828379325869685), ('little', 0.3763582412887471), ('an', 0.3659271501315764), ('stout,', 0.3545954667627708), ('and', 0.3529350265746338), ('was', 0.3456411744006594), ('with', 0.3436499498848169), ('cookshop', 0.3321788106047602), ('every', 0.32498670215739534), ('duck.', 0.3222482451464994), ('uncomfortably', 0.3205924686050286), ('built.', 0.31762111389215286), ('his', 0.31685393896125486)]\n",
      "word_name:in \n",
      "glove_top20_words:[('the', 0.41575140738021504), ('of', 0.411340383545046), ('and', 0.41120608213571025), ('midst', 0.4061819498415878), ('place', 0.4025140565861309), ('case', 0.38821896839013004), ('order', 0.3870702367667604), ('spite', 0.3859776071829679), ('found', 0.37440626625122087), ('faith', 0.37296821359433274), ('put', 0.3708203487241314), ('front', 0.3704094962726744), ('back', 0.36539572567095213), ('way', 0.3638588332166817), ('that', 0.35940676282978146), ('In', 0.35571325399195375), ('world', 0.35519552500776025), ('with', 0.3536453435233298), ('company', 0.3516465626486448), ('he', 0.35155227741868833)] \n",
      "w2v_top20_words:[('of', 0.6485634372291442), ('the', 0.6355513246147906), ('and', 0.5158938250017868), ('by', 0.44701824112871896), ('into', 0.4441542816692834), ('with', 0.4377312319784629), ('In', 0.43770417018712515), ('a', 0.43248300048031907), ('which', 0.41077727846358325), ('from', 0.4049477188234421), ('his', 0.36914362097425724), ('chilling', 0.36847496940509267), ('on', 0.3679338903500014), ('customs,', 0.355023742902468), ('namely,', 0.35299016841564784), ('constructed', 0.34911340138518615), ('befitting', 0.3469846374490602), ('Shgun', 0.3457030860222744), ('wherein', 0.3422237153226081), ('sumptuous', 0.3398066650694117)]\n",
      "word_name:I \n",
      "glove_top20_words:[('am', 0.5468114096852662), ('know', 0.5113689624534943), ('see', 0.4820541170463722), ('have', 0.4800551939404372), ('if', 0.4741036225223021), ('think', 0.47377971301872757), ('say', 0.46953357080744196), ('want', 0.46924574070130715), ('believe', 0.4689523884647591), ('wish', 0.461999632106141), ('do', 0.460207889030911), ('think,', 0.4601006791762964), ('tell', 0.45851903445319264), ('me.', 0.45785858510737437), ('mean', 0.4562441282088203), (\"don't\", 0.45470159877302896), ('thought', 0.45302659848554055), ('say,', 0.452588380617563), ('know.', 0.4505496369089615), ('should', 0.44858986982291293)] \n",
      "w2v_top20_words:[('you', 0.7260958344018836), ('me', 0.6737017163567391), ('my', 0.6507603297290792), (\"'I\", 0.5851746733620834), ('me,', 0.58174885786632), ('(I', 0.5369948844377039), ('me.', 0.5279591036562868), ('you,', 0.5262575295901618), ('am', 0.524652392112368), ('myself,', 0.5233609105858409), ('myself', 0.5145510143440986), ('myself.', 0.51035187817753), ('it', 0.5042127586385456), ('You', 0.5018583482221705), ('do', 0.49845565128390334), ('Ellen,', 0.49091093204017977), ('if', 0.478153446387332), ('you.', 0.4754779608126494), ('not', 0.472095485760926), ('your', 0.47184650743349715)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name:that \n",
      "glove_top20_words:[('that,', 0.4172522126706352), ('not', 0.40789439582200515), ('is', 0.4076701816311164), ('fact', 0.40329964039342114), ('know', 0.3958003276876628), ('this,', 0.39435918620256266), ('should', 0.39032225004092064), ('to', 0.3878726106124916), ('there', 0.3847178690742806), ('might', 0.38409146804667627), ('would', 0.38337125805036565), ('nothing', 0.38229125596329), ('could', 0.37793208333759304), ('so', 0.3777876686280142), ('same', 0.377385867841076), ('think', 0.37701299459244225), ('place', 0.37660328775849317), ('felt', 0.3762399062785963), ('case', 0.3760952913748535), ('also', 0.37573292984264617)] \n",
      "w2v_top20_words:[('it', 0.59636524095461), ('but', 0.5938647245702076), ('this', 0.5657498849910146), ('to', 0.5639183481718602), ('not', 0.5393252034617412), ('he', 0.521243656972205), ('so', 0.4981052828978609), ('when', 0.4933648488437391), ('if', 0.48524610104430943), ('beforehand,', 0.4846935113778477), ('would', 0.48195422510209796), ('even', 0.47419834132407196), ('for', 0.45903688428748185), ('what', 0.45412956104563057), ('only', 0.4494747919196943), ('because', 0.4472266984581769), ('have', 0.4404786416740192), ('be', 0.4372115978779578), ('which', 0.4329222285838194), ('should', 0.43126036163244513)]\n",
      "word_name:he \n",
      "glove_top20_words:[('said,', 0.4293148271001618), ('if', 0.41981095329688217), ('him', 0.39876034592441967), ('could', 0.3976506269556274), ('moment', 0.39589150657991606), ('saw', 0.3910356955146963), ('went', 0.3889780382948842), ('knew', 0.38513719962128695), ('when', 0.3809497714782911), ('man', 0.3784507373871995), ('him,', 0.37758068753084556), ('He', 0.3769536428798439), ('looked', 0.3766127568783823), ('replied.', 0.37375962909197674), ('thought', 0.3726627845223023), ('though', 0.36722787447158367), ('had', 0.3668719479811553), ('say', 0.36585287626183793), ('But', 0.3649648492073629), ('ought', 0.3626039307834959)] \n",
      "w2v_top20_words:[('him', 0.6760739863817782), ('his', 0.6145663354236583), ('him,', 0.5989305622941653), ('himself', 0.5651035895493012), ('she', 0.5511571142997003), ('him.', 0.5508272352158188), ('it', 0.5454914566273306), ('He', 0.523848906899353), ('that', 0.521243656972205), ('himself,', 0.4688154546121485), ('to', 0.4572292763526859), ('Smerdyakov', 0.4418046786429813), ('himself.', 0.42342538687609876), ('opponent', 0.4127984518409446), ('had', 0.39659113366284066), ('beforehand,', 0.3957231657890776), ('man', 0.3875912438531797), ('Lothario', 0.3841117745680252), ('fit.', 0.3834529938547511), ('and', 0.37931219680526157)]\n",
      "word_name:was \n",
      "glove_top20_words:[('It', 0.46866570097840593), ('There', 0.4356514136418471), ('was,', 0.4344529002631913), (\"wasn't\", 0.4214712364968767), ('knew', 0.4171047309121582), ('there', 0.4081620778163192), ('felt', 0.397417353478207), ('found', 0.3918944509048439), ('man', 0.3816173749412471), ('did', 0.3814239483522609), ('once', 0.37912940449546845), ('She', 0.3754105423793183), ('it', 0.37433753543523923), ('moment', 0.37216296012817096), ('had', 0.37176318724615004), ('that', 0.36938311761417264), ('am', 0.3686704496026867), ('thought', 0.3685816421224396), ('evidently', 0.3662935551206103), ('already', 0.3650550139887483)] \n",
      "w2v_top20_words:[('had', 0.7178516543882826), ('seemed', 0.5731261831004183), ('felt', 0.5294153894736875), ('were', 0.5276906412896569), ('saw', 0.47433338105244954), ('was,', 0.4529512067749669), ('been', 0.4483340351280002), ('could', 0.4434871320846306), ('knew', 0.42622606359324156), ('appeared', 0.4060873479553083), ('remained', 0.4046724588515817), ('came', 0.40352311935989993), ('was.', 0.4027942411242575), ('became', 0.39720207753916065), ('disliked', 0.3955296402634624), ('arrival.', 0.3855960797209856), ('recollected', 0.3827011108945649), ('found', 0.3811881751006028), ('evidently', 0.3803462122082936), ('she', 0.3776796978752919)]\n",
      "word_name:his \n",
      "glove_top20_words:[('hand', 0.4444244359538713), ('head,', 0.4340429416833892), ('hands', 0.4321403951688858), (\"master's\", 0.4191097985335182), ('him', 0.4101374594639751), (\"father's\", 0.4019204789354403), (\"wife's\", 0.3996893821501867), ('head', 0.39707810874611), (\"brother's\", 0.395757927191517), ('own', 0.39460834889914925), ('way', 0.3929647789552307), ('But', 0.38516821955765246), ('arms,', 0.3831229529039645), (\"Levin's\", 0.3771706203699672), ('hands.', 0.3765092698372101), ('own,', 0.3761443233788613), ('them', 0.37244199280224566), ('coat', 0.36998251596376464), ('heart.', 0.3695487151960422), ('pipe', 0.3693495583490835)] \n",
      "w2v_top20_words:[('he', 0.6145663354236583), ('himself', 0.5669397290360328), ('him', 0.5630809951966825), ('him,', 0.5201498917091768), ('her', 0.4808122833578192), ('girded', 0.4742277823274353), ('and', 0.4714773796131084), ('with', 0.46225407117624784), ('the', 0.45595447817988116), ('His', 0.44191495588304736), (\"latter's\", 0.43862189655338757), (\"son's\", 0.43153218608759764), ('himself,', 0.415531528865547), ('He', 0.41536913407729875), (\"Alyosha's\", 0.4099912373762389), ('clenched', 0.4083519457863043), ('ached,', 0.39776322689293137), ('his,', 0.3954060060871894), ('him.', 0.39439856634505205), ('twitching', 0.3915316486705301)]\n",
      "word_name:with \n",
      "glove_top20_words:[('filled', 0.5207479824605836), ('covered', 0.49389046615146537), ('mingled', 0.44731829813654667), ('delight', 0.406551810271531), ('smile.', 0.406506968019326), ('blood.', 0.40400135332546155), ('accordance', 0.3989254166433208), ('a', 0.39008528031634176), ('satisfied', 0.3890456417809835), ('compared', 0.38707492058933146), ('horror.', 0.3835151053607615), ('of', 0.377486496625317), ('sort', 0.37518189999956963), ('pleasure,', 0.37063148376547955), ('angry', 0.3696375601126572), ('acquainted', 0.36887398380986985), ('those', 0.36816646192510166), ('have', 0.36699868325011575), ('met', 0.36689655124403053), ('up', 0.3660707527759214)] \n",
      "w2v_top20_words:[('and', 0.5473793193299815), ('his', 0.46225407117624784), ('in', 0.4377312319784629), ('sarcastic,', 0.3709342809343748), ('knobby', 0.3691005060018203), ('the', 0.36872596200478974), ('tawny', 0.3620033636223506), ('undisguised', 0.36136783474291856), ('irrepressible', 0.35704661585847147), ('wrathful', 0.3517799844451072), ('beaming', 0.3506750475903692), ('clenching', 0.34626614131874256), ('especial', 0.3448290955125061), ('a', 0.3436499498848169), ('flushed,', 0.34319550581082947), ('sparkling', 0.34305478066801565), ('unmoved,', 0.34263634696311196), ('mourning,', 0.342340671350079), ('of', 0.34230095923090575), ('willow,', 0.3413132433160216)]\n",
      "word_name:it \n",
      "glove_top20_words:[('think', 0.5196298635222083), ('is.', 0.5162142883014628), ('it,', 0.5113180784441886), ('put', 0.49654770311963975), ('it.', 0.49491407747330995), ('if', 0.48321569641582524), ('It', 0.4823336209605673), ('was,', 0.4696615246188222), ('thought', 0.46687332321369335), ('way', 0.45890639035549297), ('all.', 0.4564808690124651), ('did', 0.45579583150193653), ('matter', 0.4539859006965326), ('know', 0.4480619716315542), ('it?', 0.4456480760620154), ('only', 0.4428355634818879), ('not', 0.44275570408968656), ('impossible', 0.44104971070097965), ('them', 0.43399784965317567), ('wish', 0.4326148111726148)] \n",
      "w2v_top20_words:[('that', 0.59636524095461), ('it,', 0.5803044252570827), ('he', 0.5454914566273306), ('it.', 0.5248284062771824), ('I', 0.5042127586385456), ('not', 0.502613665233005), ('so', 0.4952090004772976), ('if', 0.49377873691505797), ('me', 0.4703984263887535), ('to', 0.46275683693738034), ('but', 0.45500331951803996), ('him', 0.43587922672859863), ('be', 0.4165781621905281), ('she', 0.4148479892538448), ('this', 0.4075786544852884), ('what', 0.40577277815077867), ('would', 0.3961988227464802), ('should', 0.37268590653748684), ('beforehand', 0.3688120896958269), ('somehow.', 0.36783784089223914)]\n",
      "word_name:for \n",
      "glove_top20_words:[('only', 0.46584498142903275), ('sake', 0.46476233945177375), ('purpose', 0.4437966178781652), ('him', 0.43164752210149837), ('food', 0.42494777634640357), ('me', 0.42432343402393197), ('reason', 0.42142158456801776), ('if', 0.4161251802602865), ('see', 0.41510554750149614), ('it,', 0.41488877226229204), ('take', 0.41304791597344565), ('another', 0.41028546814626915), ('ever,', 0.4077353461277392), ('prepared', 0.40634892401523853), ('left', 0.40624227172299315), ('do', 0.40623950632610484), ('ever.', 0.40534799868795185), ('get', 0.405334477460616), ('I', 0.40522890186769966), ('it.', 0.40442216296324235)] \n",
      "w2v_top20_words:[('to', 0.5619678288786758), ('but', 0.5105511686307513), ('that', 0.45903688428748185), ('and', 0.42928158153814655), ('so', 0.4257805191693466), ('for.', 0.42460149436647376), ('only', 0.4102407358666197), ('would', 0.40181153255500335), ('if', 0.39705741774294917), ('not', 0.37949025508433654), ('because', 0.37151331930146614), ('should', 0.36632718151576643), ('ransomed', 0.36478419581945026), ('any', 0.3638694027373751), ('I', 0.36283960066084897), ('all', 0.3602974499322529), ('reward', 0.35952236503374024), ('it', 0.3570059580341231), ('faithfully', 0.35676111570722935), ('sorrow.', 0.3564235342547848)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name:is \n",
      "glove_top20_words:[('It', 0.48551571473387095), (\"'This\", 0.4576876731458967), ('is,', 0.4533430852410961), (\"'It\", 0.43039218895978937), ('only', 0.41382387734761283), ('say,', 0.41351603507708523), ('that', 0.4076701816311164), ('not', 0.4030019599719753), ('seems', 0.4018535093854927), ('nothing', 0.40038992299417653), (\"'That\", 0.39833499794095356), ('it', 0.3971492739561022), ('name', 0.3968965050547932), ('what', 0.392937846393788), ('For', 0.39227635054614984), ('when', 0.392197397297447), ('there', 0.39029232894997595), (\"'He\", 0.38865270858820533), ('think', 0.3824557705754615), ('truth', 0.3818278531938346)] \n",
      "w2v_top20_words:[('are', 0.5986774192574822), ('has', 0.5889665170364308), ('NOT', 0.5385920518628694), ('may', 0.5335552988938271), ('considers', 0.5324275744553368), ('will', 0.5310927721828168), ('can', 0.5302901651060834), ('does', 0.528405713189222), ('rests', 0.5211108560644138), ('argues', 0.5167651240241006), ('requires', 0.5147582742050275), ('exists', 0.5143682604551022), ('is,', 0.5090449652815786), ('belongs', 0.5071335790077316), ('proves', 0.4985961760114874), ('just.', 0.49854097995456287), ('becomes', 0.49103764371319375), ('Impossible.', 0.490114655068994), ('denies', 0.4886479560490886), ('explains', 0.48817221582534087)]\n",
      "word_name:had \n",
      "glove_top20_words:[('been', 0.5755292776257265), ('already', 0.48644331164335464), ('having', 0.48099567108307084), ('just', 0.46959805449593656), ('gone', 0.45718306156343147), ('lately', 0.4571522388928448), ('given', 0.45384298663594147), ('him.', 0.45026164878002434), ('brought', 0.44576922872640146), ('taken', 0.4395462758287098), ('could', 0.4367897167459699), ('knew', 0.4341531028346694), ('come', 0.42811446516054946), ('entered', 0.4263244420445425), ('left', 0.42566808865527983), ('once', 0.4235015166878143), ('him,', 0.4226905093601836), ('had,', 0.4225467722019649), ('felt', 0.42006287814852605), ('discovered', 0.41979370879122047)] \n",
      "w2v_top20_words:[('was', 0.7178516543882826), ('been', 0.5256714383245711), ('having', 0.5140044654715795), ('arrival.', 0.5114178582112832), ('had,', 0.46847227465866037), ('were', 0.4570144876546828), ('arrival,', 0.4507446575905303), ('could', 0.44588122544997383), ('knew', 0.4401534373989574), ('recollected', 0.43451985387850683), ('felt', 0.4311869157939478), ('previously', 0.4276060888607274), ('seemed', 0.42385323344542797), ('lately', 0.4176867003574721), ('would', 0.4107112631793257), ('before,', 0.4096829803685217), (\"hadn't\", 0.40565365276858256), ('he', 0.39659113366284066), ('visit,', 0.394156450435216), ('that', 0.3917583762160101)]\n",
      "word_name:as \n",
      "glove_top20_words:[('possible.', 0.4771120468661104), ('regarded', 0.4749523610340016), ('well', 0.4699615975627421), ('soon', 0.4697844678829593), ('though', 0.46346079412879415), ('could,', 0.44035063395977325), ('possible,', 0.4188889052281254), (\"'As\", 0.4173488631872888), ('usual,', 0.41086695031316695), ('As', 0.4073569765614558), ('could.', 0.39876809876801755), ('if', 0.39538319787088433), ('them', 0.3851543319777944), ('inasmuch', 0.3843065231812032), ('always', 0.3764090770043204), ('may', 0.37154108804361147), ('far', 0.3660777653583564), ('usual.', 0.36010463342357707), ('might', 0.35907192094399043), ('thought', 0.35657415653791735)] \n",
      "w2v_top20_words:[('so', 0.5425106049615376), ('and', 0.4764075388306864), ('though', 0.4750611743680774), ('that', 0.4214565201796624), ('but', 0.41418941123874453), ('if', 0.4054375221839747), ('could,', 0.39913764796733053), ('when', 0.38137861223601555), ('could.', 0.3808910478273176), ('as,', 0.3776248733207214), ('to', 0.37327983191833203), ('readily', 0.3730234491867983), ('nevertheless', 0.3669816964139075), ('possible.', 0.3587543731155961), ('thoroughly,', 0.35805028412071555), ('possible,', 0.3569804852277497), ('well', 0.352091086384868), ('it', 0.34878681528345745), ('very', 0.34071149576218207), ('inasmuch', 0.33922311392177285)]\n",
      "word_name:not \n",
      "glove_top20_words:[('did', 0.6064421428400627), ('could', 0.5880478144251484), ('do', 0.48768188652646455), ('does', 0.48575057863546345), ('think', 0.48016451108456704), ('know', 0.4732964151308416), ('will', 0.4652109129481983), ('wish', 0.4544555232137508), ('But', 0.4506562173126005), ('not,', 0.44642704878316947), ('should', 0.446126117327472), ('must', 0.4442975542725762), ('if', 0.4432363909987314), ('it', 0.44275570408968656), ('have', 0.4379557945034785), ('would', 0.4364891506743188), ('are', 0.4352808177302162), ('see', 0.4342859626556882), ('understand', 0.4326063837938512), ('afraid', 0.42943095150549826)] \n",
      "w2v_top20_words:[('that', 0.5393252034617412), ('but', 0.5151148596207284), ('would', 0.5090369362377222), ('it', 0.502613665233005), ('to', 0.4985766326144632), ('never', 0.4840800931855922), ('be', 0.47776831852096413), ('if', 0.47717750759199906), ('not.', 0.4755612798258897), ('not,', 0.47556092520068544), ('I', 0.472095485760926), ('only', 0.4710433493845502), ('should', 0.4655112728359877), ('did', 0.45953429794651834), ('otherwise.', 0.45238850565384847), ('so', 0.43531778882490696), ('what', 0.4342870609408056), ('you', 0.4312042897506169), ('do', 0.42851669638093404), ('no', 0.4281814059777593)]\n",
      "word_name:you \n",
      "glove_top20_words:[('do', 0.6082431858923485), ('Do', 0.5748883360503153), ('know', 0.5606321151748819), ('tell', 0.5591785380611917), ('think', 0.5549384017313943), ('you,', 0.5490176352393291), ('You', 0.5324389302283935), ('know,', 0.5255541472832717), (\"'Do\", 0.5193311202206274), (\"don't\", 0.5171672546170661), ('if', 0.5142522142589956), ('wish', 0.5065040431051843), ('If', 0.5047388105935225), ('give', 0.5043030531433985), ('want', 0.5005931476919836), ('know.', 0.4982150064981675), ('see', 0.4917711633582895), ('you?', 0.49124388550300946), ('think,', 0.48421933645538245), ('you.', 0.4795970570672917)] \n",
      "w2v_top20_words:[('I', 0.7260958344018836), ('you,', 0.7075861541501801), ('your', 0.6873918470763934), ('do', 0.679115597000292), ('You', 0.6503370715926822), ('you.', 0.6148298022497635), ('you...', 0.606150313921476), ('me', 0.5888758767687629), ('myself?', 0.5856777818431137), (\"don't\", 0.5699283526513311), (\"'I\", 0.561985772557392), ('yourself?', 0.5600238325510516), ('you?', 0.5581913121404996), ('yourself', 0.5419306135152345), ('yourself,', 0.5413164295715204), ('papa', 0.5305360929373906), ('yourselves', 0.5287418402114901), ('tell', 0.5197196234614093), ('yourself.', 0.5161873065334849), ('am', 0.5159119134478082)]\n",
      "word_name:at \n",
      "glove_top20_words:[('once.', 0.6099128988381222), ('once,', 0.5890286922222236), ('once', 0.5789057244257927), ('looked', 0.5508548334211418), ('all.', 0.5119635602837103), ('least', 0.5107217083412382), ('looking', 0.4942982271880993), ('last.', 0.486582999653398), ('least,', 0.4857931212588528), ('stared', 0.4800565593658671), ('glanced', 0.47571327521350376), ('At', 0.452120525852277), ('look', 0.45186243451772623), ('moment,', 0.4310474066790369), ('all,', 0.4285941963379938), ('arrived', 0.4281572648934433), ('him,', 0.4248672443785121), ('wonder', 0.42357008444993893), ('him', 0.4230584878706646), ('near', 0.4181359164027065)] \n",
      "w2v_top20_words:[('At', 0.5186665488222251), ('intently', 0.36883668160269556), ('stupidly', 0.3508956084877112), ('uneasily', 0.34822653601668013), ('at.', 0.3461176113904272), ('after', 0.3410689106668441), ('at,', 0.33769932048674295), (\"'At\", 0.3349712443751161), ('on', 0.33175290934700075), ('fearfully', 0.3295198250780292), ('intently,', 0.3229413057257585), ('saw', 0.31870054445678886), ('was', 0.3183776305148482), ('anxiously', 0.3164842905014252), ('inquisitively', 0.3148017621895906), (\"'at\", 0.31475443819910004), ('blankly', 0.31473162183332865), ('wildly', 0.3134353915676611), ('undisguised', 0.3103615891023506), ('with', 0.3102783363539763)]\n"
     ]
    }
   ],
   "source": [
    "for i in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, i)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, i)\n",
    "    glove = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "    print(f'word_name:{i} \\nglove_top20_words:{glove} \\nw2v_top20_words:{w2v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56031776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_distance(top20_glove, top20_w2v, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding):\n",
    "    distances = []\n",
    "    for word_glove, word_w2v in zip(top20_glove, top20_w2v):\n",
    "        embedding_glove = np.array(glove_embedding[glove_to_idx[word_glove]])\n",
    "        embedding_w2v = np.array(word2vec_embedding[word2vec_to_idx[word_w2v]])\n",
    "        distance = 1 - simcos(embedding_glove, embedding_w2v)\n",
    "        distances.append(distance)\n",
    "    return sum(distances) / len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "56b9ebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name: you\n",
      "average_cosine_distance: 0.9563079653282507\n",
      "word_name: with\n",
      "average_cosine_distance: 0.9665187201503747\n",
      "word_name: the\n",
      "average_cosine_distance: 0.9812561689149286\n",
      "word_name: is\n",
      "average_cosine_distance: 0.997775457174637\n",
      "word_name: I\n",
      "average_cosine_distance: 0.9993834369145878\n",
      "word_name: for\n",
      "average_cosine_distance: 0.9998368578794761\n",
      "word_name: a\n",
      "average_cosine_distance: 1.0011663647869011\n",
      "word_name: and\n",
      "average_cosine_distance: 1.0031730471796991\n",
      "word_name: that\n",
      "average_cosine_distance: 1.0091609679623703\n",
      "word_name: it\n",
      "average_cosine_distance: 1.009514686168777\n",
      "word_name: not\n",
      "average_cosine_distance: 1.010682822465451\n",
      "word_name: as\n",
      "average_cosine_distance: 1.0138413326443112\n",
      "word_name: in\n",
      "average_cosine_distance: 1.0155728483929467\n",
      "word_name: his\n",
      "average_cosine_distance: 1.0159914758984896\n",
      "word_name: to\n",
      "average_cosine_distance: 1.0164327174269185\n",
      "word_name: at\n",
      "average_cosine_distance: 1.0222651236301818\n",
      "word_name: of\n",
      "average_cosine_distance: 1.0276621466686489\n",
      "word_name: he\n",
      "average_cosine_distance: 1.0288282055259972\n",
      "word_name: was\n",
      "average_cosine_distance: 1.0384975363753897\n",
      "word_name: had\n",
      "average_cosine_distance: 1.0681713261321353\n"
     ]
    }
   ],
   "source": [
    "def calculate_cosine_distance(top20_glove, top20_w2v, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding):\n",
    "    distances = {}\n",
    "    for word_glove, word_w2v in zip(top20_glove, top20_w2v):\n",
    "        embedding_glove = np.array(glove_embedding[glove_to_idx[word_glove]])\n",
    "        embedding_w2v = np.array(word2vec_embedding[word2vec_to_idx[word_w2v]])\n",
    "        distance = 1 - simcos(embedding_glove, embedding_w2v)\n",
    "        distances[word_glove] = distance\n",
    "    return distances\n",
    "\n",
    "cosine_distances = {}\n",
    "for word in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, word)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, word)\n",
    "    glove_top20 = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v_top20 = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "\n",
    "    distances = calculate_cosine_distance(glove_top20, w2v_top20, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding)\n",
    "    cosine_distances[word] = sum(distances.values()) / len(distances)\n",
    "\n",
    "# Trier les mots par distance moyenne de cosinus et afficher les résultats\n",
    "for word, distance in sorted(cosine_distances.items(), key=lambda item: item[1]):\n",
    "    print(f'word_name: {word}')\n",
    "    print(f'average_cosine_distance: {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "050eeb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name: of\n",
      "average_cosine_distance: 9.45194895021987\n",
      "word_name: with\n",
      "average_cosine_distance: 9.52147478216178\n",
      "word_name: the\n",
      "average_cosine_distance: 11.704704322233525\n",
      "word_name: in\n",
      "average_cosine_distance: 12.747091941956768\n",
      "word_name: a\n",
      "average_cosine_distance: 12.917341133930648\n",
      "word_name: at\n",
      "average_cosine_distance: 13.450438788431342\n",
      "word_name: for\n",
      "average_cosine_distance: 13.683671818583045\n",
      "word_name: as\n",
      "average_cosine_distance: 13.873920951705227\n",
      "word_name: that\n",
      "average_cosine_distance: 14.134516354743326\n",
      "word_name: to\n",
      "average_cosine_distance: 14.141409515164261\n",
      "word_name: it\n",
      "average_cosine_distance: 14.2875354657349\n",
      "word_name: his\n",
      "average_cosine_distance: 14.400352057252954\n",
      "word_name: and\n",
      "average_cosine_distance: 14.730871758373913\n",
      "word_name: is\n",
      "average_cosine_distance: 15.133401763845942\n",
      "word_name: not\n",
      "average_cosine_distance: 15.838583846180393\n",
      "word_name: he\n",
      "average_cosine_distance: 16.159023448664435\n",
      "word_name: had\n",
      "average_cosine_distance: 16.66531701219059\n",
      "word_name: I\n",
      "average_cosine_distance: 17.744667541403665\n",
      "word_name: you\n",
      "average_cosine_distance: 17.991437712284917\n",
      "word_name: was\n",
      "average_cosine_distance: 19.12972153343509\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "\n",
    "def calculate_cosine_distance(top20_glove, top20_w2v, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding):\n",
    "    distances = {}\n",
    "    for word_glove, word_w2v in zip(top20_glove, top20_w2v):\n",
    "        embedding_glove = np.array(glove_embedding[glove_to_idx[word_glove]])\n",
    "        embedding_w2v = np.array(word2vec_embedding[word2vec_to_idx[word_w2v]])\n",
    "        distance = euclidean_distance(embedding_glove, embedding_w2v)\n",
    "        distances[word_glove] = distance\n",
    "    return distances\n",
    "\n",
    "cosine_distances = {}\n",
    "for word in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, word)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, word)\n",
    "    glove_top20 = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v_top20 = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "\n",
    "    distances = calculate_cosine_distance(glove_top20, w2v_top20, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding)\n",
    "    cosine_distances[word] = sum(distances.values()) / len(distances)\n",
    "\n",
    "# Trier les mots par distance moyenne de cosinus et afficher les résultats\n",
    "for word, distance in sorted(cosine_distances.items(), key=lambda item: item[1]):\n",
    "    print(f'word_name: {word}')\n",
    "    print(f'average_cosine_distance: {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d4d8f1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name: of\n",
      "average_cosine_distance: 105.30939749999996\n",
      "word_name: with\n",
      "average_cosine_distance: 105.6588586\n",
      "word_name: the\n",
      "average_cosine_distance: 130.84665644999998\n",
      "word_name: in\n",
      "average_cosine_distance: 142.44725785\n",
      "word_name: a\n",
      "average_cosine_distance: 143.6115159\n",
      "word_name: at\n",
      "average_cosine_distance: 150.18609675\n",
      "word_name: for\n",
      "average_cosine_distance: 154.2064512\n",
      "word_name: as\n",
      "average_cosine_distance: 156.41275455\n",
      "word_name: that\n",
      "average_cosine_distance: 157.62532939999997\n",
      "word_name: to\n",
      "average_cosine_distance: 158.14025435\n",
      "word_name: it\n",
      "average_cosine_distance: 158.78744220000004\n",
      "word_name: his\n",
      "average_cosine_distance: 160.26171645000002\n",
      "word_name: and\n",
      "average_cosine_distance: 165.07689394999997\n",
      "word_name: is\n",
      "average_cosine_distance: 169.01238169999993\n",
      "word_name: not\n",
      "average_cosine_distance: 177.24302185000002\n",
      "word_name: he\n",
      "average_cosine_distance: 179.97922965000004\n",
      "word_name: had\n",
      "average_cosine_distance: 187.2405591\n",
      "word_name: I\n",
      "average_cosine_distance: 195.91381959999998\n",
      "word_name: you\n",
      "average_cosine_distance: 196.80317265\n",
      "word_name: was\n",
      "average_cosine_distance: 213.1321414\n"
     ]
    }
   ],
   "source": [
    "def manhattan_distance(a, b):\n",
    "    return np.sum(np.abs(a - b))\n",
    "\n",
    "\n",
    "def calculate_cosine_distance(top20_glove, top20_w2v, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding):\n",
    "    distances = {}\n",
    "    for word_glove, word_w2v in zip(top20_glove, top20_w2v):\n",
    "        embedding_glove = np.array(glove_embedding[glove_to_idx[word_glove]])\n",
    "        embedding_w2v = np.array(word2vec_embedding[word2vec_to_idx[word_w2v]])\n",
    "        distance = manhattan_distance(embedding_glove, embedding_w2v)\n",
    "        distances[word_glove] = distance\n",
    "    return distances\n",
    "\n",
    "cosine_distances = {}\n",
    "for word in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, word)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, word)\n",
    "    glove_top20 = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v_top20 = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "\n",
    "    distances = calculate_cosine_distance(glove_top20, w2v_top20, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding)\n",
    "    cosine_distances[word] = sum(distances.values()) / len(distances)\n",
    "\n",
    "# Trier les mots par distance moyenne de cosinus et afficher les résultats\n",
    "for word, distance in sorted(cosine_distances.items(), key=lambda item: item[1]):\n",
    "    print(f'word_name: {word}')\n",
    "    print(f'average_cosine_distance: {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f85ff0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "def calculate_average_euclidean_distance(top20_glove, top20_w2v, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding):\n",
    "    distances = []\n",
    "    for (word_glove, _), (word_w2v, _) in zip(top20_glove, top20_w2v):\n",
    "        embedding_glove = np.array(glove_embedding[glove_to_idx[word_glove]])\n",
    "        embedding_w2v = np.array(word2vec_embedding[word2vec_to_idx[word_w2v]])\n",
    "        dist = euclidean_distance(embedding_glove, embedding_w2v)\n",
    "        distances.append(dist)\n",
    "    return sum(distances) / len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_distance(top20_glove, top20_w2v, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding):\n",
    "    distances = []\n",
    "    for word_glove, word_w2v in zip(top20_glove, top20_w2v):\n",
    "        embedding_glove = np.array(glove_embedding[glove_to_idx[word_glove]])\n",
    "        embedding_w2v = np.array(word2vec_embedding[word2vec_to_idx[word_w2v]])\n",
    "        distance = 1 - simcos(embedding_glove, embedding_w2v)\n",
    "        distances.append(distance)\n",
    "    return sum(distances) / len(distances)\n",
    "\n",
    "\n",
    "for word in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, word)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, word)\n",
    "    glove_top20 = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v_top20 = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "\n",
    "    cosine_distance = calculate_cosine_distance(glove_top20, w2v_top20, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding)\n",
    "\n",
    "\n",
    "# Trier les mots par distance moyenne de cosinus et afficher les résultats\n",
    "for word, distance in sorted(cosine_distances.items(), key=lambda item: item[1]):\n",
    "    print(f'word_name: {word}')\n",
    "    print(f'average_cosine_distance: {distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a2c1b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name: the\n",
      "average_euclidean_distance: 11.704704322233525\n",
      "word_name: and\n",
      "average_euclidean_distance: 14.730871758373913\n",
      "word_name: of\n",
      "average_euclidean_distance: 9.45194895021987\n",
      "word_name: to\n",
      "average_euclidean_distance: 14.141409515164261\n",
      "word_name: a\n",
      "average_euclidean_distance: 12.917341133930648\n",
      "word_name: in\n",
      "average_euclidean_distance: 12.747091941956768\n",
      "word_name: I\n",
      "average_euclidean_distance: 17.744667541403665\n",
      "word_name: that\n",
      "average_euclidean_distance: 14.134516354743326\n",
      "word_name: he\n",
      "average_euclidean_distance: 16.159023448664435\n",
      "word_name: was\n",
      "average_euclidean_distance: 19.12972153343509\n",
      "word_name: his\n",
      "average_euclidean_distance: 14.400352057252954\n",
      "word_name: with\n",
      "average_euclidean_distance: 9.52147478216178\n",
      "word_name: it\n",
      "average_euclidean_distance: 14.2875354657349\n",
      "word_name: for\n",
      "average_euclidean_distance: 13.683671818583045\n",
      "word_name: is\n",
      "average_euclidean_distance: 15.133401763845942\n",
      "word_name: had\n",
      "average_euclidean_distance: 16.66531701219059\n",
      "word_name: as\n",
      "average_euclidean_distance: 13.873920951705227\n",
      "word_name: not\n",
      "average_euclidean_distance: 15.838583846180393\n",
      "word_name: you\n",
      "average_euclidean_distance: 17.991437712284917\n",
      "word_name: at\n",
      "average_euclidean_distance: 13.450438788431342\n"
     ]
    }
   ],
   "source": [
    "for word in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, word)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, word)\n",
    "    glove_top20 = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v_top20 = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "\n",
    "    avg_euclidean_distance = calculate_average_euclidean_distance(glove_top20, w2v_top20, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding)\n",
    "\n",
    "    print(f'word_name: {word}')\n",
    "    print(f'average_euclidean_distance: {avg_euclidean_distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88ff2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(set1, set2):\n",
    "    intersection = len(set(set1) & set(set2))\n",
    "    union = len(set(set1) | set(set2))\n",
    "    return 1 - intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9388316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name: as\n",
      "jaccard_distance: 0.75\n",
      "word_name: had\n",
      "jaccard_distance: 0.7878787878787878\n",
      "word_name: not\n",
      "jaccard_distance: 0.7878787878787878\n",
      "word_name: you\n",
      "jaccard_distance: 0.7878787878787878\n",
      "word_name: and\n",
      "jaccard_distance: 0.8235294117647058\n",
      "word_name: was\n",
      "jaccard_distance: 0.8235294117647058\n",
      "word_name: in\n",
      "jaccard_distance: 0.8571428571428572\n",
      "word_name: that\n",
      "jaccard_distance: 0.8571428571428572\n",
      "word_name: he\n",
      "jaccard_distance: 0.8571428571428572\n",
      "word_name: a\n",
      "jaccard_distance: 0.8888888888888888\n",
      "word_name: I\n",
      "jaccard_distance: 0.8888888888888888\n",
      "word_name: it\n",
      "jaccard_distance: 0.8888888888888888\n",
      "word_name: the\n",
      "jaccard_distance: 0.9189189189189189\n",
      "word_name: of\n",
      "jaccard_distance: 0.9189189189189189\n",
      "word_name: for\n",
      "jaccard_distance: 0.9189189189189189\n",
      "word_name: to\n",
      "jaccard_distance: 0.9473684210526316\n",
      "word_name: with\n",
      "jaccard_distance: 0.9473684210526316\n",
      "word_name: his\n",
      "jaccard_distance: 0.9743589743589743\n",
      "word_name: is\n",
      "jaccard_distance: 0.9743589743589743\n",
      "word_name: at\n",
      "jaccard_distance: 0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer la distance de Jaccard\n",
    "def jaccard_distance(set1, set2):\n",
    "    intersection = len(set(set1) & set(set2))\n",
    "    union = len(set(set1) | set(set2))\n",
    "    return 1 - intersection / union\n",
    "\n",
    "# Calculer et stocker les distances de Jaccard\n",
    "jaccard_distances = {}\n",
    "for word in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, word)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, word)\n",
    "    glove_top20 = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v_top20 = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "\n",
    "    jaccard_dist = jaccard_distance(glove_top20, w2v_top20)\n",
    "    jaccard_distances[word] = jaccard_dist\n",
    "\n",
    "# Trier les mots par la distance de Jaccard et afficher les résultats\n",
    "for word, distance in sorted(jaccard_distances.items(), key=lambda item: item[1]):\n",
    "    print(f'word_name: {word}')\n",
    "    print(f'jaccard_distance: {distance}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12c8df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(a, b):\n",
    "    return np.sum(np.abs(a - b))\n",
    "\n",
    "def calculate_average_manhattan_distance(top20_glove, top20_w2v, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding):\n",
    "    distances = []\n",
    "    for (word_glove, _), (word_w2v, _) in zip(top20_glove, top20_w2v):\n",
    "        embedding_glove = np.array(glove_embedding[glove_to_idx[word_glove]])\n",
    "        embedding_w2v = np.array(word2vec_embedding[word2vec_to_idx[word_w2v]])\n",
    "        distance = manhattan_distance(embedding_glove, embedding_w2v)\n",
    "        distances.append(distance)\n",
    "    return sum(distances) / len(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cec093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_name: the\n",
      "average_manhattan_distance: 130.84665644999998\n",
      "word_name: and\n",
      "average_manhattan_distance: 165.07689394999997\n",
      "word_name: of\n",
      "average_manhattan_distance: 105.30939749999996\n",
      "word_name: to\n",
      "average_manhattan_distance: 158.14025435\n",
      "word_name: a\n",
      "average_manhattan_distance: 143.6115159\n",
      "word_name: in\n",
      "average_manhattan_distance: 142.44725785\n",
      "word_name: I\n",
      "average_manhattan_distance: 195.91381959999998\n",
      "word_name: that\n",
      "average_manhattan_distance: 157.62532939999997\n",
      "word_name: he\n",
      "average_manhattan_distance: 179.97922965000004\n",
      "word_name: was\n",
      "average_manhattan_distance: 213.1321414\n",
      "word_name: his\n",
      "average_manhattan_distance: 160.26171645000002\n",
      "word_name: with\n",
      "average_manhattan_distance: 105.6588586\n",
      "word_name: it\n",
      "average_manhattan_distance: 158.78744220000004\n",
      "word_name: for\n",
      "average_manhattan_distance: 154.2064512\n",
      "word_name: is\n",
      "average_manhattan_distance: 169.01238169999993\n",
      "word_name: had\n",
      "average_manhattan_distance: 187.2405591\n",
      "word_name: as\n",
      "average_manhattan_distance: 156.41275455\n",
      "word_name: not\n",
      "average_manhattan_distance: 177.24302185000002\n",
      "word_name: you\n",
      "average_manhattan_distance: 196.80317265\n",
      "word_name: at\n",
      "average_manhattan_distance: 150.18609675\n"
     ]
    }
   ],
   "source": [
    "for word in top:\n",
    "    glove_sim = calculate_sim(glove_embedding, glove_to_idx, word)\n",
    "    word2vec_sim = calculate_sim(word2vec_embedding, word2vec_to_idx, word)\n",
    "    glove_top20 = get_top20_words(glove_sim, glove_vovab)\n",
    "    w2v_top20 = get_top20_words(word2vec_sim, word2vec_vovab)\n",
    "\n",
    "    avg_manhattan_distance = calculate_average_manhattan_distance(glove_top20, w2v_top20, glove_to_idx, word2vec_to_idx, glove_embedding, word2vec_embedding)\n",
    "\n",
    "    print(f'word_name: {word}')\n",
    "    print(f'average_manhattan_distance: {avg_manhattan_distance}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
